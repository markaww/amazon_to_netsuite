{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please provide a start date yyyy/mm/dd 2021-05-04\n",
      "please provide an end date yyyy/mm/dd 2021-05-18\n",
      "please provide Brand Viridescent\n",
      "please provide Customer 14 Amazon - UK\n",
      "please provide a tranId, eg CS100 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995 rows exported! Check your folder!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.io import gbq\n",
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "# Import the mapping tables\n",
    "\n",
    "subsidiaries = pd.read_csv('/home/markaw/Heroes/ns_cashsales/subsidiaries.csv')\n",
    "customers = pd.read_csv('/home/markaw/Heroes/ns_cashsales/Customer.csv', encoding='iso-8859-1')\n",
    "heroesID =  pd.read_csv(r'/home/markaw/Heroes/ns_cashsales/heroesID.csv', encoding='iso-8859-1')\n",
    "\n",
    "# provide variables for BQ extract\n",
    "\n",
    "start_dt = input('please provide a start date yyyy/mm/dd')\n",
    "end_dt = input('please provide an end date yyyy/mm/dd')\n",
    "\n",
    "while True:\n",
    "    brand = input('please provide Brand')\n",
    "    if brand not in subsidiaries['Brand'].tolist():\n",
    "        print('Please check the spelling for that brand')\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "while True:\n",
    "    customer = input('please provide Customer')\n",
    "    if customer not in customers['Customer reference'].tolist():\n",
    "        print('That customer seems incorrect, check spelling')\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# tranId = input('please provide a tranId, eg CS100')\n",
    "        \n",
    "# Run BQ extract \n",
    "\n",
    "sql_query = f\"\"\"\n",
    "SELECT * \n",
    "FROM analytics-298917.analytics_models.f_amz_order_items\n",
    "\n",
    "WHERE purchase_dt BETWEEN '{start_dt}' AND '{end_dt}'\n",
    "\"\"\"\n",
    "bq_raw = gbq.read_gbq(sql_query, project_id = \"analytics-298917\")\n",
    "bq = bq_raw[(bq_raw['order_status'] != 'Cancelled') & \n",
    "            (bq_raw['sales_channel'] != 'Non-Amazon') &\n",
    "            (bq_raw['quantity'] != 0)].reset_index()\n",
    "\n",
    "\n",
    "# Create a draft NetSuite CashSale import template\n",
    "\n",
    "columns = ['tranId','customerTEMP','tranDate','Mon','Year','currencyRef','exchangeRate',\n",
    "'isTaxable','itemLine_itemRefTEMP','itemLine_quantity','itemLine_unitsRef','itemLine_salesPrice','itemLine_priceLevelRef',\n",
    "'Subsiduary','Expected Deposit date']\n",
    "\n",
    "template = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Bring BQ data into the template\n",
    "\n",
    "template['customerTEMP'] = bq['sales_channel']\n",
    "template['tranDate'] = bq['purchase_dt'].apply(lambda x: x.strftime(\"%d/%m/%Y\"))\n",
    "template['Mon'] = bq['purchase_dt'].apply(lambda x: x.strftime(\"%b\")[0:3])\n",
    "template['Year'] = bq['purchase_dt'].apply(lambda x: x.year)\n",
    "template['currencyRef'] = bq['currency']\n",
    "template['exchangeRate'] = 1\n",
    "template['isTaxable'] = 'TRUE'\n",
    "template['itemLine_itemRefTEMP'] = bq['asin']\n",
    "template['itemLine_quantity'] = bq['quantity']\n",
    "template['itemLine_unitsRef'] = 'Units'\n",
    "template['itemLine_salesPrice']= bq['item_price_local']/bq['quantity']\n",
    "template['itemLine_priceLevelRef'] = 'Custom'\n",
    "template['Subsiduary'] = bq['brand_name']\n",
    "template['Expected Deposit date'] = (bq['purchase_dt'].max()+datetime.timedelta(days=15)).strftime(\"%d/%m/%Y\")\n",
    "template['tranId'] = tranId\n",
    "\n",
    "\n",
    "# Merge template with information from the mapping tables\n",
    "\n",
    "merged = pd.merge(template,subsidiaries, left_on='Subsiduary', right_on='Brand', how='inner')\n",
    "merged1 = pd.merge(merged,customers, left_on='customerTEMP', right_on='Sales channel', how='inner')\n",
    "merged2 = pd.merge(merged1,heroesID, left_on='itemLine_itemRefTEMP', right_on='ASIN', how='inner')\n",
    "merged2['locationRef'] = 'Amazon FBA - ' + merged2['Acronym'] +' - '+ merged2['Country Code']\n",
    "\n",
    "# Filter by desired customer ID\n",
    "\n",
    "customer_filter = merged2[(merged2['Customer reference'] == customer) & (merged2['Brand'] == brand)].copy()\n",
    "\n",
    "# Modify country ticker for US/UK or else the will both populate the template as UNI\n",
    "\n",
    "if customer == '14 Amazon - UK':\n",
    "    customer_filter['Country'] = 'UK'\n",
    "elif customer == '16 Amazon - US':\n",
    "    customer_filter['Country'] = 'US'\n",
    "\n",
    "# Select the columns we need and re-make the final import template\n",
    "\n",
    "final_dict = {\n",
    "    'ExternalID': f\"\"\"{customer_filter.iloc[0][13][0:3].upper()}{date.today().strftime(\"%d%m%Y\")}{customer_filter.iloc[0][19][0:3].upper()}\"\"\",\n",
    "    'tranId':' ',\n",
    "    'customerRef':customer_filter['Customer reference'],\n",
    "    'tranDate':customer_filter['tranDate'],\n",
    "    'postingPeriodRef':customer_filter['Mon'] +\" \"+customer_filter['Year'].astype(str),\n",
    "    'currencyRef':customer_filter['currencyRef'],\n",
    "    'exchangeRate':customer_filter['exchangeRate'],\n",
    "    'locationRef':customer_filter['locationRef'],\n",
    "    'isTaxable':customer_filter['isTaxable'],\n",
    "    'itemLine_itemRef':customer_filter['NEW (FINAL) HEROES ID'],\n",
    "    'itemLine_quantity':customer_filter['itemLine_quantity'],\n",
    "    'itemLine_unitsRef':customer_filter['itemLine_unitsRef'],\n",
    "    'itemLine_salesPrice':customer_filter['itemLine_salesPrice'],\n",
    "    'itemLine_priceLevelRef':customer_filter['itemLine_priceLevelRef'],\n",
    "    'Subsiduary':customer_filter['Code'],\n",
    "    'Expected Deposit date':customer_filter['Expected Deposit date'],\n",
    "}\n",
    "\n",
    "# Create the final dataframe template\n",
    "\n",
    "final = pd.DataFrame(final_dict).reset_index()\n",
    "\n",
    "# Export 'final' to csv, splitting it if >5k (NetSuite import limit)\n",
    "\n",
    "if len(final) < 5000:\n",
    "    name = f'/home/markaw/Heroes/ns_cashsales/CS Templates/{customer_filter.iloc[0][13][0:3].upper()}{date.today().strftime(\"%d%m%Y\")}{customer_filter.iloc[0][19][0:3].upper()}.csv'\n",
    "    final.to_csv(name, index=False)\n",
    "    \n",
    "elif 5000 <= len(final) < 10000:\n",
    "    name = f'/home/markaw/Heroes/ns_cashsales/CS Templates/{customer_filter.iloc[0][13][0:3].upper()}{date.today().strftime(\"%d%m%Y\")}{customer_filter.iloc[0][19][0:3].upper()}1.csv'\n",
    "    final[0:5000].to_csv(name, index=False)\n",
    "    \n",
    "    name2 = f'/home/markaw/Heroes/ns_cashsales/CS Templates/{customer_filter.iloc[0][13][0:3].upper()}{date.today().strftime(\"%d%m%Y\")}{customer_filter.iloc[0][19][0:3].upper()}2.csv' \n",
    "    final2 = final[(final.index >= 5001) & ((final.index < 10000))].copy()\n",
    "    final2['ExternalID'] = final['ExternalID']+'b'\n",
    "#     final2['tranId'] = \"CS\"+str(int(final['tranId'][0][-3:])+1)\n",
    "    final2.to_csv(name2, index=False)\n",
    "    \n",
    "elif len(final) >= 10000:\n",
    "    name = f'/home/markaw/Heroes/ns_cashsales/CS Templates/{customer_filter.iloc[0][13][0:3].upper()}{date.today().strftime(\"%d%m%Y\")}{customer_filter.iloc[0][19][0:3].upper()}1.csv'\n",
    "    final[0:5000].to_csv(name, index=False)\n",
    "    \n",
    "    name2 = f'/home/markaw/Heroes/ns_cashsales/CS Templates/{customer_filter.iloc[0][13][0:3].upper()}{date.today().strftime(\"%d%m%Y\")}{customer_filter.iloc[0][19][0:3].upper()}2.csv' \n",
    "    final2 = final[(final.index >= 5001) & ((final.index < 10000))].copy()\n",
    "    final2['ExternalID'] = final['ExternalID']+'b'  \n",
    "#     final2['tranId'] = \"CS\"+str(int(final['tranId'][0][-3:])+1)\n",
    "    final2.to_csv(name2, index=False)\n",
    "    \n",
    "    name3 = f'/home/markaw/Heroes/ns_cashsales/CS Templates/{customer_filter.iloc[0][13][0:3].upper()}{date.today().strftime(\"%d%m%Y\")}{customer_filter.iloc[0][19][0:3].upper()}3.csv' \n",
    "    final3 = final[(final.index > 10000)].copy()\n",
    "    final3['ExternalID'] = final['ExternalID']+'c' \n",
    "#     final3['tranId'] = \"CS\"+str(int(final['tranId'][0][-3:])+2) \n",
    "    final3.to_csv(name3, index=False)\n",
    "\n",
    "\n",
    "print(f'{len(final)} rows exported! Check your folder!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DAV-TLP-WW-ZZ-68', 'DAV-SPS-WW-ZZ-SE', 'DAV-RLP-WW-ZZ-60',\n",
       "       'DAV-RHS-WW-ZZ-SE', 'DAV-SHE-WW-ZZ-NA', 'DAV-RHS-WW-ZZ-NA',\n",
       "       'DAV-RCS-WW-ZZ-NA', 'DAV-SRS-WW-ZZ-NA', 'DAV-HWS-WW-ZZ-NA',\n",
       "       'DAV-GRS-WW-ZZ-SE', 'DAV-PHS-WW-ZZ-NA', 'DAV-TLP-WW-ZZ-63',\n",
       "       'DAV-PSW-WW-GN-NA', 'DAV-TSP-WW-ZZ-NA', 'DAV-PSW-WW-RD-NA',\n",
       "       'DAV-CBS-WW-ZZ-NA', 'DAV-PSW-WW-ZZ-25', 'DAV-RST-WW-ZZ-SE'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['itemLine_itemRef'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:heroes_env]",
   "language": "python",
   "name": "conda-env-heroes_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
